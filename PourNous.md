# Introduction

Ce fichier n'est pas destinÃ© Ã  Ãªtre push sur le repo, il est juste lÃ  pour que nous comprenons ce que nous faisons.

## Ã‰tape 1

Fichier `MLP_from_raw_data.ipynb`

### ğŸ¯ Objectif global de l'Ã©tape 1

Lâ€™objectif est de classer des images de chiffres manuscrits (`MNIST`) en utilisant un rÃ©seau de neurones multicouches (`MLP`). On commence avec des donnÃ©es "brutes", câ€™est-Ã -dire les pixels directement, sans traitement prÃ©alable.

### ğŸ”¢ Pourquoi utiliser les pixels comme entrÃ©e ?

- Une image `MNIST` est composÃ©e de `28x28 = 784 pixels`, en niveaux de gris.
- Chaque pixel contient une information importante : câ€™est la reprÃ©sentation directe du chiffre.
- Utiliser les pixels bruts permet de tester la capacitÃ© du rÃ©seau Ã  apprendre sans aide extÃ©rieure (pas d'extraction manuelle de caractÃ©ristiques).

### ğŸ§  Pourquoi un `MLP` (Multilayer Perceptron) ?

- Le `MLP` est une architecture simple et standard en deep learning, utile pour Ã©tablir une base de comparaison.
- Il est dit â€œshallowâ€ ici car il ne contient quâ€™une seule couche cachÃ©e.
- Il permet dâ€™apprendre des relations non linÃ©aires entre pixels et classes (0 Ã  9).

### ğŸ—ï¸ Pourquoi tester plusieurs tailles de couches cachÃ©es (128, 256, 512) ?

- Une plus grande couche cachÃ©e permet de mieux approximer des fonctions complexesâ€¦ mais :
    - demande plus de temps d'entraÃ®nement.
    - augmente le risque de surapprentissage (`overfitting`).
- Tester diffÃ©rentes tailles permet dâ€™Ã©quilibrer capacitÃ© de gÃ©nÃ©ralisation et complexitÃ©.

### âš™ï¸ Pourquoi utiliser softmax en sortie ?

- Il s'agit d'une classification multiclasse (10 classes).
- La couche softmax retourne une probabilitÃ© par classe, ce qui permet dâ€™interprÃ©ter la sortie comme une prÃ©diction.

### ğŸ§® Pourquoi categorical_crossentropy comme fonction de perte ?

- Câ€™est la fonction de perte adaptÃ©e aux problÃ¨mes de classification multiclasse avec one-hot encoding.
- Elle mesure l'Ã©cart entre la distribution prÃ©dite (softmax) et la vÃ©ritÃ© terrain (one-hot).

### ğŸ“ˆ Pourquoi visualiser accuracy et courbe de perte ?

Cela permet de :

- vÃ©rifier si le modÃ¨le apprend bien (val_accuracy â†‘, val_loss â†“),
- dÃ©tecter un overfitting (val_accuracy stagne ou diminue alors que train_accuracy â†‘).

### ğŸ” Pourquoi une matrice de confusion ?

- Elle permet d'analyser finement les erreurs du modÃ¨le.
- Elle montre quelles classes sont confondues entre elles, ce qui Ã©claire les limites du modÃ¨le.

## Ã‰tape 2

Fichier `MLP_from_HOG.ipynb`

### ğŸ¯ Objectif global de l'Ã©tape 2

Lâ€™objectif est toujours de classer des chiffres manuscrits (`MNIST`) mais cette fois-ci **en extrayant des caractÃ©ristiques (features)** Ã  lâ€™aide de `HOG` avant dâ€™entraÃ®ner un `MLP`.  
On cherche Ã  comparer lâ€™approche *brute* (pixels) avec une approche *basÃ©e sur des descripteurs visuels*.

---

### ğŸ§ª Pourquoi utiliser `HOG` (Histogram of Oriented Gradients) ?

- HOG est une mÃ©thode classique dâ€™extraction de caractÃ©ristiques visuelles.
- Elle dÃ©crit les **bords et contours** prÃ©sents dans une image.
- Elle est plus **invariante aux variations locales** (bruit, petites dÃ©formations) que les pixels bruts.
- Elle permet au MLP dâ€™apprendre sur des **informations plus compactes et discriminantes**.

---

### âš™ï¸ Pourquoi tester plusieurs `pix_per_cell` (4 et 7) ?

- Ce paramÃ¨tre dÃ©termine la **rÃ©solution locale de dÃ©tection des gradients** :
  - Une petite cellule (4x4) capte plus de dÃ©tails.
  - Une grande cellule (7x7) donne une reprÃ©sentation plus globale.
- Comparer ces deux tailles permet de **mesurer lâ€™impact de la granularitÃ© des descripteurs** sur les performances du rÃ©seau.

---

### ğŸ”¢ Pourquoi standardiser les features (`StandardScaler`) ?

- Les valeurs de HOG peuvent varier selon lâ€™intensitÃ© des pixels et la taille des cellules.
- La standardisation (moyenne = 0, Ã©cart-type = 1) :
  - accÃ©lÃ¨re lâ€™apprentissage,
  - stabilise lâ€™optimiseur,
  - empÃªche quâ€™une dimension domine les autres.

---

### ğŸ§  Pourquoi encore un `MLP` ?

- Le but est de comparer les mÃªmes types de modÃ¨les (**shallow MLP**) mais avec des **entrÃ©es diffÃ©rentes** (pixels bruts vs. HOG).
- Cela permet de voir si lâ€™extraction de features amÃ©liore ou dÃ©tÃ©riore la performance dâ€™un rÃ©seau simple.

---

### ğŸ—ï¸ Pourquoi tester plusieurs tailles de couches cachÃ©es (128, 256, 512) ?

- MÃªme logique que pour lâ€™Ã©tape 1 : tester la capacitÃ© dâ€™approximation du rÃ©seau en fonction du nombre de neurones.

---

### ğŸ“Š Pourquoi comparer les courbes et matrices de confusion ?

- Comme Ã  lâ€™Ã©tape 1, cela permet de :
  - suivre la **convergence de lâ€™apprentissage**,
  - identifier les **chiffres mal classÃ©s** malgrÃ© les features HOG,
  - **comparer objectivement avec les rÃ©sultats obtenus avec les pixels bruts**.

---

### âš–ï¸ Conclusion

Cette Ã©tape permet de comprendre :

- Lâ€™intÃ©rÃªt dâ€™utiliser des descripteurs (comme HOG) en entrÃ©e dâ€™un rÃ©seau,
- Les impacts des choix de paramÃ¨tres (cellule, neurones),
- Comment lâ€™extraction de features modifie la performance dâ€™un rÃ©seau simple.

## Ã‰tape 3
